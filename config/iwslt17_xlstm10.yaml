# config/iwslt17_xlstm10.yaml

training:
  seed: 1337
  batch_size: 16
  num_epochs: 10
  lr: 5e-4
  weight_decay: 1e-3
  grad_clip: 1.0
  patience_epochs: 3
  num_workers: 4
  min_delta: 0.001

dataset:
  vocab_size: 8000
  max_src_len: 128
  max_tgt_len: 128

model:
  num_blocks: 4
  embedding_dim: 256

  # mLSTM sub-block config
  mlstm_block:
    mlstm:
      conv1d_kernel_size: 4
      qkv_proj_blocksize: 4
      num_heads: 4

  # no sLSTM at all â†’ 1:0
  slstm_block: {}
  slstm_at: []

  # will be reset by max_src_len / max_tgt_len
  context_length: 128
